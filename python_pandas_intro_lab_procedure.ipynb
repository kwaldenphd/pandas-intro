{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNIijtLIIu+s8x2jMIK3TVz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwaldenphd/pandas-intro/blob/main/python_pandas_intro_lab_procedure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Started With `pandas` (in Python)\n",
        "\n",
        "<a href=\"http://creativecommons.org/licenses/by-nc/4.0/\" rel=\"license\"><img style=\"border-width: 0;\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" alt=\"Creative Commons License\" /></a>This tutorial was written by Katherine Walden and is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc/4.0/\" rel=\"license\">Creative Commons Attribution-NonCommercial 4.0 International License</a>.\n"
      ],
      "metadata": {
        "id": "xcULCvzjrZUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Overview & Goals\n",
        "\n",
        "This lab covers the core components of `pandas`, including `Series` and `DataFrame` objects. It covers how to manually create and interact with `Series` and `DataFrame` objects in the Python programming environment. It covers loading a structured data file (CSV and JSON) as a `DataFrame`, and sorting, selecting, and filtering the resulting `DataFrame`. The lab also covers common data parsing and wrangling challenges like duplicate entries and missing data.\n",
        "\n",
        "By the end of this lab, students will be able to;\n",
        "- Understand the basic components of `Series` and `DataFrame` objects in `pandas`\n",
        "- Manually create `Series` and `DataFrame` objects in Python using `pandas`\n",
        "- Load a structured data file as a `DataFrame` in Python using `pandas`\n",
        "- Interact with a `DataFrame` using sorting, selecting, and filtering operations\n",
        "- Remove duplicate rows from a `DataFrame`\n",
        "- Understand how to approach common `DataFrame` parsing and loading errors using `pandas`\n",
        "- Understand the basic components of how to handle missing values in a `DataFrame`\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=da5b8c14-e546-44fd-8f65-af36014781ce\">Lecture/live coding playlist</a></td>\n",
        "  </tr>\n",
        "  </table>"
      ],
      "metadata": {
        "id": "Bx0wHz3traUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acknowledgements\n",
        "\n",
        "Information and exercises in this lab were developed in consultation with the following resources:\n",
        "- `pandas` package [\"Getting started\"](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/) documentation.\n",
        "- Wes McKinney's [*Python for Data Analysis: Data Wrangling With pandas, Numpy, and IPython*](https://www.oreilly.com/library/view/python-for-data/9781491957653/) (O'Reilly, 2017)\n",
        "  * Chapter 5 \"Getting Started with pandas\" (125-168)\n",
        "  * Chapter 7 \"Data Cleaning and Preparation\" (195-224)\n",
        "  * Chapter 8 \"Data Wrangling: Join, Combine, and Reshape\" (225-256)\n",
        "  * Chapter 10 \"Data Aggregation and Group Operations\" (293-322)\n"
      ],
      "metadata": {
        "id": "zjDcFNKSrejT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture & Live Coding\n",
        "\n",
        "Throughout this lab, you will see a Panopto icon at the start of select sections.\n",
        "\n",
        "This icon indicates there is lecture/live coding asynchronous content that accompanies this section of the lab. \n",
        "\n",
        "You can click the link in the figure caption to access these materials (ND users only).\n",
        "\n",
        "Example:\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=da5b8c14-e546-44fd-8f65-af36014781ce\">Lecture/live coding playlist</a></td>\n",
        "  </tr>\n",
        "  </table>"
      ],
      "metadata": {
        "id": "J-IQI7OZUeBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Notebook Template\n",
        "\n",
        "[Click here](https://colab.research.google.com/drive/1sKrGhGa_uvJw7l4QiKGKP-X_sAMlcQrq?usp=sharing) to access the lab notebook template as a Jupyter Notebook (Google Colab, ND Users)"
      ],
      "metadata": {
        "id": "30YIQw7NrnFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Submit This Lab (and show your work)\n",
        "\n",
        "Moving forward, we're going to be submitting lab notebooks using the provide Jupyter Notebook template ([link for this lab's template](https://colab.research.google.com/drive/1sKrGhGa_uvJw7l4QiKGKP-X_sAMlcQrq?usp=sharing)).\n",
        "- If working in JupyterLab (or another desktop IDE), download the `.ipynb` file to your local computer\n",
        "  * `File` - `Download` - `Download as .ipynb`\n",
        "- If working in Google Colaboratory, MAKE SURE you save a copy to your local drive. Otherwise your changes will not be saved.\n",
        "  * `File` - `Save a copy in Drive`\n",
        "\n",
        "The lab notebook template includes all of the questions as well as pre-created markdown cells for narrative text answers and pre-created code cells for any programs you may need to create. \n",
        "- Double click on these cells to edit and add your own content\n",
        "- If questions do not require a code component, you can ignore those cells\n",
        "- If questions to not require a narrative component, you can ignore those cells\n",
        "\n",
        "If working in JupyterLab or another desktop IDE, upload the lab notebook template `.ipynb` file to Canvas as your lab submission.\n",
        "- NOTE: This lab also asks you to upload a PDF version of this notebook. You are welcome, but not required, to do that moving forward.\n",
        "\n",
        "If working in Google Colaboratory, submit the link to your notebook (checking sharing permissions, similar with Google Docs) AS WELL AS the `.ipyb` file"
      ],
      "metadata": {
        "id": "800f05kwrogp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=1a39dca8-2d61-4f20-b6e8-af360144f447\">Overview</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "<p align=\"center\"><img src=\"https://github.com/kwaldenphd/pandas-intro/blob/main/images/Peebo.png?raw=true\" width=\"1000\"></p>\n",
        "\n",
        "Some of you may be wondering why we are talking about pandas in a Computer Science course....\n",
        "\n",
        "Panda: \"a large black-and-white mammal (Ailuropoda melanoleuca) of chiefly central China that feeds primarily on bamboo shoots and is now usually classified with the bears (family Ursidae)\" ([Merriam-Webster](https://www.merriam-webster.com/dictionary/panda))\n",
        "\n",
        "Wait that's not right....\n",
        "\n",
        "`pandas`: \"a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language\" ([`pandas` documentation](https://pandas.pydata.org/))\n",
        "\n",
        "That makes more sense.\n",
        "\n",
        "If you remember back to our earlier work with `.csv` files in Python, there are limitations to the kinds of things we can do with structured data using the `csv` module. Particularly if we want to analyze and visualze structured data in a Python programming environment, we aren't going to get very far loading `csv` files as lists or dictionaries. We need Python to understand or interact with structured data as structured data."
      ],
      "metadata": {
        "id": "npInfIDyrqfD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter `pandas`! \n",
        "\n",
        "Software developers at AQR Capital Management began working on a Python-based tool (written in a combination of C and Python) for quantitative data analysis in 2008. The initial open-source version of `pandas` was released in 2008.\n",
        "\n",
        "At its core, \"`pandas` is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series\" ([Wikipedia](https://en.wikipedia.org/wiki/Pandas_(software)). The name `pandas` is derived from \"panel data,\" an econometrics term used to describe particular types of datasets. The name `pandas` is also a play on \"Python data analysis.\"\n",
        "\n",
        "For more on the history and origins of `pandas`, check out Wes McKinney's [\"pandas: a Foundational Python Library for Data Analysis and Statistics\"](https://www.dlr.de/sc/Portaldata/15/Resources/dokumente/pyhpc2011/submissions/pyhpc2011_submission_9.pdf) 2011 paper.\n",
        "\n",
        "`pandas` is based on and has some similarities with another Python package, `NumPy`. According to [package documentation](https://numpy.org/doc/stable/user/whatisnumpy.html), \"`NumPy` is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\"\n",
        "\n",
        "In `NumPy`, data are stored as list-like objects called arrays. `NumPy` allows users to access, split, reshape, join, etc. data stored in arrays. `pandas` takes a similar approach to structured data, or data organized in a tabular (i.e. table-like) format. \"pandas adopts significant parts of NumPy's idiomatic style of array-based computing, especially array-based functions and a preference for data processing without for loops...the biggest difference is that pandas is designed for working with tabular or heterogeneous data. NumPy, by contrast, is best suited for working with homogenous numerical array data\" (Wes McKinney, Chapter 5 \"Getting Started with Pandas\" in *Python for Data Analysis*, pg. 125)\n",
        "\n",
        "For more on `NumPy`:\n",
        "- [NumPy website](https://numpy.org/)\n",
        "- [NumPy documentation](https://numpy.org/doc/stable/)\n",
        "- [\"NumPy Introduction,\" W3Schools](https://www.w3schools.com/python/numpy_intro.asp)\n",
        "- [\"Introduction to NumPy Tutorial,\" Software Carpentry](https://software-carpentry.org/blog/2012/06/introduction-to-numpy-tutorial.html)"
      ],
      "metadata": {
        "id": "PajRpEl3rr3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Structures in `pandas`\n",
        "\n",
        "<p align=\"center\"><img src=\"https://github.com/kwaldenphd/pandas-intro/blob/main/images/series_df_diagram.png?raw=true\" width=\"1000\"></p>\n",
        "\n",
        "`pandas` has two main data structures: `Series` and `DataFrame`.\n",
        "- \"A `Series` is a one-dimensional, array-like object containing a sequence of values...and an associated array of data labels, called its index\" (McKinney, 126)\n",
        "- A `DataFrame` includes a tabular data structure \"and contains an ordered collection of columns, each of which can be a different value type\" (McKinney, 130)."
      ],
      "metadata": {
        "id": "MMoJ_Wf9rtFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Series`\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a6057ced-9dd1-426c-a063-af360146b0dd\">Series</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "In `pandas`, \"a `Series` is a one-dimensional, array-like object containing a sequence of values...and an associated array of data labels, called its index\" (McKinney, 126). At first glance, a `Series` looks a lot like a Python list."
      ],
      "metadata": {
        "id": "ee5ihoNGrt-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas package\n",
        "import pandas as pd\n",
        "\n",
        "# import Series and Data Frame components from pandas\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "# create a Series using pandas\n",
        "obj = pd.Series([4, 7, -5, 3])\n",
        "\n",
        "# show obj Series \n",
        "obj"
      ],
      "metadata": {
        "id": "K8zNavhurvJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few notes on what's happening in this example:\n",
        "- We imported the `pandas` package (using the `pd` alias) as well as the specific `Series` and `DataFrame` components.\n",
        "- We created a `Series` object containing four integer values.\n",
        "\n",
        "We could create a list with these values, but for data analysis we needed the functionality `pandas` provides for working with series. To verify `obj` is stored as an array-like object, we can use `pd.Series(obj).values` which should return `array([4, 7, -5, 3])`\n",
        "\n",
        "We can also get the index attributes for `obj` using `pd.Series(obj).index`, which should return `RangeIndex(start=0, stop=4, step=1)`. The default index attributes assigned to objects in an array are integers `0` through `N-1`, where `N` is the length of the data. We can create our own index attributes for the data points by manually creating index labels.\n"
      ],
      "metadata": {
        "id": "mEd_oGiHrwbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create obj2 series with index attributes\n",
        "obj2 = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c'])\n",
        "\n",
        "# show obj2 series\n",
        "obj2"
      ],
      "metadata": {
        "id": "hG6m-uwHrxq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The index-value link lets us interact with a `Series` object similar to how we would work with Python dictionary key-value pairs."
      ],
      "metadata": {
        "id": "jANd0Sq3ry-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# access Series value using index label\n",
        "obj2['a'] \n",
        "\n",
        "# this returns -5"
      ],
      "metadata": {
        "id": "weAzEa8Yrzxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign value for index\n",
        "obj2['d'] = 6\n",
        "\n",
        "obj2['d']\n",
        "\n",
        "# this returns 6, our newly-assigned value for index 'd'"
      ],
      "metadata": {
        "id": "pBCf6qcer1II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# access multiple values in Series object using index\n",
        "obj2[['c', 'a', 'd']]\n",
        "\n",
        "# this returns the index-value pairs for the specified index labels"
      ],
      "metadata": {
        "id": "vVInpKPNr2aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use Python's built-in arithmetic functionality for values in a `Series` object. "
      ],
      "metadata": {
        "id": "lU9iU_tNr3UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select values in the Series that meet a specific condition\n",
        "obj2[obj2 > 0]\n",
        "\n",
        "# returns index-value pairs for values greater than 0"
      ],
      "metadata": {
        "id": "tE9I5Lm4r4QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply all values in Series\n",
        "obj * 2\n",
        "\n",
        "# returns modified values"
      ],
      "metadata": {
        "id": "_UPGipRnr5Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform NumPy's exponent calculation functionality on Series values\n",
        "np.exp(obj2)\n",
        "\n",
        "# returns exponent float values"
      ],
      "metadata": {
        "id": "todBuTAtr6DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to perform similar mathematical operations on values stored in a Python dictionary or list and you'll run into all kinds of data type errors. The `Series` object uses a similar data structure and opens up a wide range of analysis possibilities.\n",
        "\n",
        "To create a `Series` from data in a Python dictionary:\n"
      ],
      "metadata": {
        "id": "zMzUSlJkr7Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionary\n",
        "sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\n",
        "\n",
        "# create Series from dict dictionary\n",
        "obj3 = pd.Series(sdata)"
      ],
      "metadata": {
        "id": "rOp7w8Cir9D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we wanted to have the `Series` values appear in a specific order. We can specify the index (or key) label order when converting a dictionary to a Series."
      ],
      "metadata": {
        "id": "LvbD1fu8r93O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionary\n",
        "sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\n",
        "\n",
        "# list of index labels\n",
        "states = ['California', 'Ohio', 'Oregon', 'Texas']\n",
        "\n",
        "# create Series from dict dictionary\n",
        "obj4 = pd.Series(sdata, index=states)\n",
        "\n",
        "# see output for new obj4 series\n",
        "obj4"
      ],
      "metadata": {
        "id": "TuyPEWesr-1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few things have happened here.\n",
        "- The `California` index is returning `NaN` for its value, which is \"not a number\" or \"NA\".\n",
        "- The `Utah` value in `sdata` is not in the `obj4` series, because the idex label `Utah` was not in the manually assigned list of index values passed to the series through `index=true`.\n",
        "\n",
        "We can use the `isnull()` or `notnull()` functions in `pandas` to detect missing data. These functions will return `TRUE` or `FALSE`."
      ],
      "metadata": {
        "id": "au6O7EzVsALy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test for null values for each index label\n",
        "pd.isnull(obj4)\n",
        "\n",
        "# output will be FALSE for all but California"
      ],
      "metadata": {
        "id": "l8igNCA1sBRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test for not null values\n",
        "pd.notnull(obj4)\n",
        "\n",
        "# output will be TRUE for all but California"
      ],
      "metadata": {
        "id": "GdnFAB6hsCG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can assign a name for our `Series` object and its index values using the `name` attribute."
      ],
      "metadata": {
        "id": "SzLwjsTKsC45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# assign name to Series object\n",
        "obj4.name = 'population'\n",
        "\n",
        "# assign name to index\n",
        "obj4.index.name = 'state'\n",
        "\n",
        "# view updated Series\n",
        "obj4"
      ],
      "metadata": {
        "id": "6uGMVMgmsDsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output for `obj4` now reflects our newly-assigned `name` attribute values.\n",
        "\n",
        "#### Application\n",
        "\n",
        "Q1: Describe a `Series` object in your own words.\n",
        "\n",
        "Q2: Create your own `Series` object. Write code the accomplishes the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Assign unique index attributes for each series value\n",
        "- Access a series value(s) using the index label\n",
        "- Perform at least two unique arithmetic operations on the Series\n",
        "- Test for null values in your series"
      ],
      "metadata": {
        "id": "qfUvGmXvsE9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `DataFrame`\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=96293510-c88d-4444-a8d0-af360146c587\">DataFrame</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "While a `Series` object is a one-dimensional array, a `DataFrame` includes a tabular data structure \"and contains an ordered collection of columns, each of which can be a different value type\" (McKinney, 130). A `pandas` `DataFrame` has a row and column index--we can think of these as Series that all share the same index. Behold, a two-dimensional data structure!\n",
        "\n",
        "In most situations, you'll create a `DataFrame` by reading in a structured data file. But we're going to manually create a `DataFrame` to better understand how they work in `pandas`. Let's go back to our state population data example. Say we have two dictionaries that include equal-length lists:\n"
      ],
      "metadata": {
        "id": "4nBT7J0MsGiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionary with three equal-length lists\n",
        "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'], \n",
        "        'year': [2000, 2001, 2002, 2001, 2002, 2003],\n",
        "        'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
        "\n",
        "# write data dictionary values to data frame\n",
        "frame = pd.DataFrame(data)\n",
        "\n",
        "# show newly-created frame\n",
        "frame"
      ],
      "metadata": {
        "id": "HJda1JwbsGIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Behold, a two-dimensional `DataFrame` object with rows, columns, labels, and values. The first object from each of the lists in our `data` dictionary now populate the first row of our `frame` DataFrame. This pattern continues for subsequent rows.\n",
        "\n",
        "We can start to explore the dimensions or overall characteristics of our DataFrame:"
      ],
      "metadata": {
        "id": "FgCOkl30sIvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shows index labels and values for first 5 rows\n",
        "frame.head(5)\n",
        "\n",
        "# shows list of column labels\n",
        "frame.columns.values\n",
        "\n",
        "# shows basic statistical information for the data frame\n",
        "frame.describe()"
      ],
      "metadata": {
        "id": "X3U2lA-esJhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last command `.describe()` returns some statistical information about values in our dataset, including:\n",
        "- count\n",
        "- mean\n",
        "- standard deviation\n",
        "- minimum\n",
        "- 25th percentile\n",
        "- 50th percentile\n",
        "- 75th percentile\n",
        "- maximum\n",
        "\n",
        "Let's say we want to specify the column sequence or the order in which columns are arranged in the `DataFrame`:"
      ],
      "metadata": {
        "id": "wtbCDJsLsK1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data, columns=['year', 'state', 'pop'])"
      ],
      "metadata": {
        "id": "wkKlYhyAsL5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens if we specify a column that isn't represented in the data passed to the `DataFrame`? "
      ],
      "metadata": {
        "id": "A6UobSRXsMx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create new dataframe from data dictionary with specific columns and index labels\n",
        "frame2 = pd.DataFrame(data, columns=['year', 'state', 'pop', 'debt'], index=['one', 'two', 'three', 'four', 'five', 'six'])\n",
        "\n",
        "# show frame2 DataFrame\n",
        "frame2"
      ],
      "metadata": {
        "id": "0uOPRnuYsN10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see only `NaN` missing values for the `debt` column since that column is not represented in the `data` dictionary used to create our `frame2` DataFrame.\n",
        "\n",
        "We can select columns in our `DataFrame` using their index labels."
      ],
      "metadata": {
        "id": "cAQMPQ6JsOwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame2['state']\n",
        "\n",
        "# returns state column"
      ],
      "metadata": {
        "id": "isLNlf02sQBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also select a column using the `name` attribute."
      ],
      "metadata": {
        "id": "0d91o4yvsRd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame2.year\n",
        "\n",
        "# returns year column"
      ],
      "metadata": {
        "id": "ihO0yhtrsSUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can retrieve rows based on their position using the `loc` (location) attribute."
      ],
      "metadata": {
        "id": "87pCh_g6sTW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame2.loc['three']\n",
        "\n",
        "# returns the third row in the dataframe"
      ],
      "metadata": {
        "id": "33UUxM4TsUGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame2.iloc[0:3, :]\n",
        "\n",
        "# uses numerical index values to retrieve first four rows"
      ],
      "metadata": {
        "id": "tGIUF5KIsVLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we wanted to manually assign the values in a particular column, for example the `debt` missing data column."
      ],
      "metadata": {
        "id": "s7y8XdVysV6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame2['debt'] = 16.5\n",
        "\n",
        "frame2\n",
        "\n",
        "# returns frame2 DataFrame with newly-assigned 16.5 value for all rows in debt column"
      ],
      "metadata": {
        "id": "LsGtwoUosXgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could also manually insert values for specific rows using their index labels. If we wanted to add debt values for rows two, four, and five:"
      ],
      "metadata": {
        "id": "QeehA8TlsYV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# variable with Series object\n",
        "val = pd.Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five'])\n",
        "\n",
        "# assign val Series object to debt column in frame2 DataFrame\n",
        "frame2['debt'] = val\n",
        "\n",
        "# show modified DataFrame\n",
        "frame2"
      ],
      "metadata": {
        "id": "9zcIvgrgsZH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now see the modified `debt` values for the rows specified in the `index=` portion of our code.\n",
        "\n",
        "We can remove a column using the `del` keyword."
      ],
      "metadata": {
        "id": "k0KLkJOQsZ_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del frame2['debt']\n",
        "\n",
        "# returns updated list of columns\n",
        "frame2.columns\n",
        "\n",
        "# result will be 'year', 'state', and 'pop'"
      ],
      "metadata": {
        "id": "M4xpcEmcsa4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Application\n",
        "\n",
        "Q3: Describe a DataFrame in your own words.\n",
        "\n",
        "Q4: Create your own small DataFrame. Write code that accomplishes the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Change the original column order\n",
        "- Select a specific column(s) using its index label or name attribute\n",
        "- Select a specific row(s) using its index label or index value\n",
        "- Remove a column from the DataFrame\n",
        "- Determine summary statistics for values in the DataFrame"
      ],
      "metadata": {
        "id": "moBM65T0scQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From Data File to `DataFrame`\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=01168562-ebe4-4516-89ef-af3601451832\">From Data File to DataFrame</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "As mentioned earlier in this lab, it's far more likely that you will load structured data from a file into Python, rather than manually creating a `DataFrame`. For this section of the lab, we're going to work with data about *Titanic* passengers. Navigate to https://raw.githubusercontent.com/kwaldenphd/pandas-intro/main/data/titanic.csv in a web browser to see the dataset.\n",
        "\n",
        "We can load structured data into Python from a file located on our computer or from a URL, using `pd.read_csv()`. An example of how we would load the `titanic.csv` file in Python as a `Pandas` DataFrame:\n"
      ],
      "metadata": {
        "id": "W-YyGiUMsdZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load titanic data from csv file\n",
        "# titanic = pd.read_csv(\"titanic.csv\")\n",
        "\n",
        "# load titanic data from url\n",
        "titanic = pd.read_csv(\"https://raw.githubusercontent.com/kwaldenphd/pandas-intro/main/data/titanic.csv\")\n",
        "\n",
        "# show first 5 rows of newly-loaded dataframe\n",
        "titanic.head(5)"
      ],
      "metadata": {
        "id": "F9yJMSfAselB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`pandas` provides the `read_csv()` function which stores `.csv` data as a `pandas` `DataFrame`. This `read_` prefix can be used with other structured data file formats, as we'll explore with JSON later.\n",
        "\n",
        "Other parsing functions in `pandas`:\n",
        "- `read_fwf`: fixed-width data with no delimiter\n",
        "- `read_clipboard`: reads in data from clipboard\n",
        "- `read_excel`: reads in data from `.xls` or `.xlsx` files\n",
        "- `read_html`: reads in any tables contained in an HTML document\n",
        "- `read_json`: reads in JSON data\n",
        "- `read_sql`: reads in results of an SQL query as a pandas dataframe\n",
        "- `read_sas`: reads in SAS dataset\n",
        "- `read_stata`: reads in Stata file format\n",
        "\n",
        "To check the first and last five rows of the `titanic` data frame:"
      ],
      "metadata": {
        "id": "ujQfGZY7sgEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic"
      ],
      "metadata": {
        "id": "05NLvpAssgfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check the data type for each column using `.dtypes`."
      ],
      "metadata": {
        "id": "U1IzD1o7shyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.dtypes"
      ],
      "metadata": {
        "id": "P5mChx2Csiah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this output, we know we have integers (`int64`), floats (`float64`), and strings (`object`). Maybe we want a more technical summary of this `DataFrame`."
      ],
      "metadata": {
        "id": "K6LRPK6hsjHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.info()"
      ],
      "metadata": {
        "id": "z-vBsnddsj3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.info()` returns row numbers, the number of entries, column names, column data types, and the number of non-null values in each column. We can see from the `Non-Null Count` values that some columns do have null or missing values. `.info()` also tells us how much memory (RAM) is used to store this `DataFrame`.\n",
        "\n",
        "## Application\n",
        "\n",
        "Q5: Write code that loads in a different `.csv` file as a DataFrame and accomplishes each of the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Shows the first five rows\n",
        "- Shows the last five rows\n",
        "- Checks the data types for each column\n",
        "- Returns a technical summary for the DataFrame"
      ],
      "metadata": {
        "id": "-8T6WFbbskt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Data Loading Challenges\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=7947cc62-3264-43da-afe4-af360147f936\">Other Data Loading Challenges</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "We can also run into situations where the data we are loading into Python has missing values. We can specify what characters representing missing data when we create the `DataFrame`."
      ],
      "metadata": {
        "id": "2KtGHARisoJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load data where missing values are represented by NA or Null\n",
        "sample = pd.read_csv(\"file_name.csv\", na_values=['NA', 'Null'])\n",
        "\n",
        "# for a situation where missing values in one column are represented by NA and another column's missing data are represented by Null\n",
        "# first step is to create a dictionary for these column names and null values\n",
        "null_symbols = {'column1': ['NA'], 'column2': ['Null']}\n",
        "\n",
        "# load data where with column-specific missing values\n",
        "sample2 = pd.read_csv(\"file_2_name.csv\", na_values=null_symbols)"
      ],
      "metadata": {
        "id": "xS47Il4LspT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`pd.read_csv` includes other function arguments that can help with other common data formatting issues.\n",
        "\n",
        "Argument | Description\n",
        "--- | ---\n",
        "`sep` or `delimiter` | Specifies the character sequence or regular expression used as a separator or delimiter\n",
        "`header` | Specifies the row number to use as column names; `0` is default (does not need to be specified); `header=None` if no header\n",
        "`index_col` | Specifies the column numbers or names to use as row index \n",
        "`names` | Specifies list of column names for result\n",
        "`skiprows` | Row numbers (starting at 0) for rows to skip\n",
        "`na_values` | Sequence of characters that represent missing or NA data\n",
        "`comment` | Characters used to mark or split off comments that occur at end of lines of data\n",
        "`parse_dates` | Specifies how date and time data will be parsed; `False` by default; `True` will attempt to parse all columns as `datetime` format; can also apply to select columns\n",
        "`dayfirst` | Specifies international date format (DD/MM/YYYY); `False` by default\n",
        "`date_parser` | Function used to parse dates\n",
        "`nrows` | Number of rows to read starting at the beginning of the file; especially helpful when only needing part of a large file\n",
        "`skipfooter` | Number of lines to ignore at the end of the file\n",
        "`encoding` | Specifies encoding schema\n",
        "`thousands` | Specifies `,` or `.` separater for thousands\n",
        "\n",
        "Other elements of `.csv` dialect we might encounter when loading a file to a `DataFrame`:\n",
        "\n",
        "Argument | Description\n",
        "--- | ---\n",
        "`delimiter` | One character string used to separate fields; default is `,`\n",
        "`quotechar` | Quote character for fields with specific characters or fields that inclde the delimiter character\n",
        "`skippinitialspace` | Instructs program to ignore whitespace after delimiter; default is `False`\n",
        "`doublequote` | Specifies how to handle quoting character within a field\n",
        "`escapechar` | Specifies the string used to escape the delimiter character if `quoting` is set to `QUOTE_NONE`\n",
        "\n",
        "### Application\n",
        "\n",
        "For the Q6 programs, you do not need to write code that actually loads an existing data file. That is, the lab does not provide data files that include these structures/attributes.\n",
        "\n",
        "Write sample code that shows the syntax you would use to load a file with the structures/attributes described in the question.\n",
        "\n",
        "For example, your answers might look something like the sample syntax shown in the previous section of the lab..\n",
        "\n",
        "HINT: Be prepared to reference and consult the additional pd.read_csv function arguments listed in the previous lab section's tables.\n",
        "\n",
        "Q6A: Write code that loads in a structured data file that uses a pipe symbol (|) as a delimiter. Include code + comments.\n",
        " \n",
        "Q6B: Write code that loads in structured data file in which missing data values are represented by \"?\", \"??\", and \"-\" characters. Include code + comments.\n",
        "\n",
        "Q6C: Write code that ignores the last 6 rows of a structured data file. Include code + comments.\n",
        "\n",
        "Q6D: Write code that parses a structured data file in which commas \",\" are used as a thousands separator. Include code + comments"
      ],
      "metadata": {
        "id": "UlnzNSdbsrfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interacting with a `DataFrame`"
      ],
      "metadata": {
        "id": "9RiaXjPWsuAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sorting\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=480927f9-34c6-436d-8971-af360146f634\">Sorting</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "`pandas` includes a few different built-in sorting operations. We can sort by an index for either axis of our `DataFrame` (i.e. we can sort based on row index labels or by column name). Going back to our Titanic passenger data, let's say we wanted to sort by passenger age."
      ],
      "metadata": {
        "id": "KdopEvK5su6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load titanic data from url\n",
        "titanic = pd.read_csv(\"https://raw.githubusercontent.com/kwaldenphd/eda-pandas/main/data/titanic.csv\")\n",
        "\n",
        "# show first 5 rows of newly-loaded dataframe\n",
        "titanic.head(5)\n",
        "\n",
        "# sort by passenger age and show first five rows of the sorted data\n",
        "titanic.sort_values(by=\"Age\").head()"
      ],
      "metadata": {
        "id": "g8n_UMn5sv3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default for `.sort_values` is to sort in ascending order. We can use `ascending=False` to sort in descending order."
      ],
      "metadata": {
        "id": "B2djDG2hswsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.sort_values(by=['Age'], ascending=False)"
      ],
      "metadata": {
        "id": "kipkPQpksxSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: When sorting, we are returning a sorted `DataFrame`. We ARE NOT updating the `DataFrame` in place. We have a couple of options to sort in place."
      ],
      "metadata": {
        "id": "jpAttcrfsx0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create new dataframe with sorted results\n",
        "titanic_by_age = titanic.sort_values(by=\"Age\")\n",
        "\n",
        "# check newly-created dataframe\n",
        "titanic_by_age.head()"
      ],
      "metadata": {
        "id": "DqCwF9bQsyvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort values in place\n",
        "titanic.sort_values(['Age'], inplace=True)\n",
        "\n",
        "# check newly-created dataframe\n",
        "titanic.head()"
      ],
      "metadata": {
        "id": "f4a43ckgs0EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also sort by multiple fields. To sort by class cabin and age, in descending order:"
      ],
      "metadata": {
        "id": "zvCT9Sjps0_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "titanic.sort_values(by=['Pclass', 'Age'], ascending=False).head()"
      ],
      "metadata": {
        "id": "-0qntzSDs2DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When sorting by fields with string data, `a-z` is considered `ascending` and `z-a` would be `descending`."
      ],
      "metadata": {
        "id": "s-Ad44ENs2nq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subsetting"
      ],
      "metadata": {
        "id": "qu6gH7Ays3X8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=b2805333-207c-4cc2-9238-af360146fd12\">Select</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "To review, we can select specific columns from a `DataFrame`. "
      ],
      "metadata": {
        "id": "dJ2q-g5Es4VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creates Series object with age values\n",
        "ages = titanic[\"Age\"]\n",
        "\n",
        "# show new object\n",
        "ages"
      ],
      "metadata": {
        "id": "iFpRXNJOs5B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use `[\" \"]` to select a specific single column of interest. Python returns this single column's data as a `Series` object. We can also create a new data frame based on multiple columns."
      ],
      "metadata": {
        "id": "uPqW4vxqs6L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selects multiple columns to form new dataframe\n",
        "age_sex = titanic[[\"Age\", \"Sex\"]]\n",
        "\n",
        "# checks first five rows of new dataframe\n",
        "age_sex.head()"
      ],
      "metadata": {
        "id": "bLcbGzlKs7B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When selecting multiple columns, the inner brackets (`[]`) define the column names to subset or select. The outer brackets select data from a dataframe. In this multi-column example, `age_sex` is a `DataFrame` because it is a two-dimensional object.\n",
        "\n",
        "For more on sorting operations in `pandas`, check out the package's [\"Sorting\" documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#sorting).\n",
        "\n",
        "### Filter\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=9570d7eb-5363-4bca-89ef-af360147074d\">Filter</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "We can use Python's comparison operators to return rows in our `DataFrame` that meet specific conditions. Let's say we wanted to create a new `DataFrame` only containing data for passengers older than 35 years."
      ],
      "metadata": {
        "id": "OsLqNb3Fs8Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "above_35 = titanic[titanic[\"Age\"] > 35]\n",
        "\n",
        "# check first five rows of newly-created dataframe\n",
        "above_35.head()"
      ],
      "metadata": {
        "id": "G8SQ7RvSs8z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use brackets (`[]`) to set a condition rows must meet to be assigned to the new dataframe. If we just wanted to see whether rows meet this condition in the original `DataFrame`, we could just test for the condition without creating a new `DataFrame`."
      ],
      "metadata": {
        "id": "9D_9Iymhs9x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic[\"Age\"] > 35"
      ],
      "metadata": {
        "id": "YO3HaHNds-jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maybe we want to create a new data frame containing data on passegers in cabin class 2 and 3."
      ],
      "metadata": {
        "id": "mq9rCLc9s_Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_23 = titanic[titanic[\"Pclass\"].isin([2, 3])]\n",
        "\n",
        "# check first five rows of newly-created dataframe\n",
        "class_23.head()"
      ],
      "metadata": {
        "id": "6ECd_E2JtAOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `isin()` conditional function on its own would return a `True` or `False` value. By nesting the `isin()` function in brackets (`[]`), we are filtering rows based on rows  that meet the function critera, or return as `True` from this function.\n",
        "\n",
        "We could also break out the chained or compound conditional statement using an `OR` operator, `|`."
      ],
      "metadata": {
        "id": "36VYAYjLtBjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_23_alternate =  titanic[(titanic[\"Pclass\"] == 2) | (titanic[\"Pclass\"] == 3)]\n",
        "\n",
        "class_23_alternate.head()"
      ],
      "metadata": {
        "id": "l5v22rzgtCdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more on Boolean indexing and the `isin()` function:\n",
        "- [\"Boolean indexing,\" Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-boolean)\n",
        "- [\"Indexing with isin,\" Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-basics-indexing-isin)\n",
        "\n",
        "We could also create a new dataframe with passenger data for only passengers that have a known age."
      ],
      "metadata": {
        "id": "tg0LHCe0tDpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "age_known = titanic[titanic[\"Age\"].notna()]\n",
        "\n",
        "age_known.head()"
      ],
      "metadata": {
        "id": "VnkLv-sxtE99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.notna()` is a conditional function that returns `True` for rows that do not have a `Null` value. For more on missing values and related functions, check out [the \"Working with missing data\" package documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#missing-data)."
      ],
      "metadata": {
        "id": "RwyCvRPvtF_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting specific rows and columns\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a2d95af5-1c38-427b-8251-af360147393c\">Selecting Specific Rows & Columns</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "Selecting lets us isolate columns, and filtering identifies specific rows. But we can imagine a scenario in which we would want to combine these elements. We might want to create a new dataframe containing only the names of passengers who are over 35 years old."
      ],
      "metadata": {
        "id": "HIxd6abbtHa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "over_35_names = titanic.loc[titanic[\"Age\"] > 35, \"Name\"]\n",
        "\n",
        "over_35_names"
      ],
      "metadata": {
        "id": "AGLAOMg-tIGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.loc` identifies the rows we are writing to the new dataframe. What we are passing to the `loc` operator includes the row filter condition (`titanic[\"Age\"] > 35`) and the column we are writing to the new dataframe (`Name`). \n",
        "\n",
        "We can also select rows and columns based on their index position. We could isolate rows 10-25 and columns 3-5 with the following expression:"
      ],
      "metadata": {
        "id": "2OgL0t5etJSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.iloc[9:25, 2:5]"
      ],
      "metadata": {
        "id": "ysWhqFSttKFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also assign new values to our selection using `loc` or `iloc`. `loc` isolates rows based on their value, while `iloc` isolates rows based on their index position or label. Let's say we wanted to anonymize the first three names in the dataset. We could do this using `titanic.iloc[0:3, 3] = \"anonymous\"`.\n",
        "\n",
        "Consult the [\"Different choices for indexing\"](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-choice) documentation for more on indexing options.\n",
        "\n",
        "A few key takeaways:\n",
        "- We use square brackets `[]` to subset data.\n",
        "- We can specify single rows or columns, a list of rows/columns, or conditional expression within those brackets\n",
        "- Select specific rows and/or columns using `loc` when working with row/column names\n",
        "- Select specific rows and/or columns usign `iloc` when working with index positions\n",
        "- You can assign new values to selection using `loc` or `iloc`\n",
        "\n",
        "## From `DataFrame` to Data File\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=bbd847e6-f649-43fb-ad8c-af3601480776\">Selecting From DataFrame to Data File</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "Let's say we have data in a `DataFrame` and want to write that to a file. While `.read_` loads data, `.to_` writes data. \n",
        "\n",
        "Let's say we want to save our filtered `DataFrame` as an Excel file."
      ],
      "metadata": {
        "id": "dzwOmGJvtLz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(\"df.xlsx\", sheet_name=\"data\", index=False)"
      ],
      "metadata": {
        "id": "V716hSzItMy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we create a new Excel file with a single sheet (`data`) that stores the data from our `df` `DataFrame`. `index=False` means that row index labels are not included in the new spreadsheet.\n",
        "\n",
        "We could load back in the new Excel file and write it to a `.csv` file, dropping the header row:"
      ],
      "metadata": {
        "id": "zWNjRi3ytOU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load Excel file as dataframe\n",
        "df = pd.read_excel(\"df.xlsx\", sheet_name=\"data\")\n",
        "\n",
        "# write dataframe to CSV file with no header\n",
        "df.to_csv(\"df.csv\", header=False, index=False)"
      ],
      "metadata": {
        "id": "29AvfJoXtRfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application\n",
        "\n",
        "Q7A: Using the DataFrame you created for Q5, write code that executes AT LEAST FOUR of the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Sorts a column by ascending values\n",
        "- Sorts a column by descending values\n",
        "- Selects a specific column in the DataFrame\n",
        "- Creates a new DataFrame with select columns from existing DataFrame\n",
        "- Uses a comparison operator to filter rows in the DataFrame\n",
        "- Uses an isin statement to filter rows in the DataFrame\n",
        "- Selects specific rows and columns\n",
        "\n",
        "Q7B: Write your modified `DataFrame` from Q7A to a `.csv` file. Your answer for these items should include a Python program + comments that document process and explain your code."
      ],
      "metadata": {
        "id": "V0Rt_vPNtTDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other `DataFrame` Tasks\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=71580603-99cd-46f6-bfa3-af360147553e\">Other DataFrame Tasks</a></td>\n",
        "  </tr>\n",
        "  </table>"
      ],
      "metadata": {
        "id": "min4U0QHtT3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Duplicates\n",
        "\n",
        "A useful place to start is identifying and removing any duplicate rows in a dataframe. We can do this using a few key functions. `.duplicated()` will return a `True` or `False` value indicating if a row is a duplicate of a previously occuring row."
      ],
      "metadata": {
        "id": "9n8pbWD5tiQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.duplicated()"
      ],
      "metadata": {
        "id": "GZxFFNSItj8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.drop_duplicates()` will return a dataframe containing only rows that are not duplicated."
      ],
      "metadata": {
        "id": "f0onWUbCtk4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_frame = old_data_frame.drop_duplicates()"
      ],
      "metadata": {
        "id": "L9InseA_tliJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Missing Data\n",
        "\n",
        "As mentioned previously, we can specify how `pandas` handles missing values when working with a data frame object."
      ],
      "metadata": {
        "id": "FbJBniJStm5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `.dropna()`\n",
        "\n",
        "We can use `.dropna()` to drop any row containing a missing value:"
      ],
      "metadata": {
        "id": "f9PJXvKBtn8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_na = data_frame.dropna()"
      ],
      "metadata": {
        "id": "XARETyHNtor3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To drop any column containing a missing value, we can specify the axis:"
      ],
      "metadata": {
        "id": "F_krkI7ztp4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_na_columns = data_frame.dropna(axis=1, how='all')"
      ],
      "metadata": {
        "id": "A0c4UZPutqoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `.fillna()`\n",
        "\n",
        "But we can imagine a scenario in which you don't want to filter out missing data. The `.fillna()` function will replace missing data with a specified value. The default function will replace all missing data in the dataframe:\n"
      ],
      "metadata": {
        "id": "u2TVAmDRtsJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replaces all missing data with 0\n",
        "df.fillna(0)"
      ],
      "metadata": {
        "id": "h9QL0xR2ts6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also specify a different missing fill value for specific columns using a dictionary."
      ],
      "metadata": {
        "id": "Tp6TpDGfttlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace missing data in column 1 with 0.5 value and in column 2 with 0\n",
        "df.fillna({1: 0.5, 2: 0})"
      ],
      "metadata": {
        "id": "LRgrYb_3tujC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In these examples, `.fillna()` returns a new object, but we can also modify the existing object in-place by setting `inplace` to `True`."
      ],
      "metadata": {
        "id": "dY2WwotYtvl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modify existing object in-place\n",
        "df.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "NAbor-OQtwON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also copy (or propogate) the last valid observation into missing data using specific methods that go along with `.fillna()`.\n",
        "- Fill Forward (`ffill`) will take the \"last known value\" and apply it to missing data entries, until you hit the next non-null observation in the data frame.\n",
        "- Back Fill (`bfill`) goes the other direction, starting from the last row in the dataset. The \"last known value\" is applied to missing data entries until you hit the next non-null observation.\n",
        "\n",
        "To use forward fill on all missing values in a dataframe:"
      ],
      "metadata": {
        "id": "0Lb4rE6htxU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(method='ffill')"
      ],
      "metadata": {
        "id": "Ho69ZWHbtyBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use back fill on all missing values in a dataframe:"
      ],
      "metadata": {
        "id": "dl6qkgyttyqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(method='bfill')"
      ],
      "metadata": {
        "id": "bNl4TTx8tzS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application\n",
        "\n",
        "Q8A: Using the DataFrame you created for Q5 (and used in Q7), write code that executes AT LEAST ONE of the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "\n",
        "- Removes duplicate rows\n",
        "- Removes rows with missing values\n",
        "- Fills missing values using .fillna, ffill, or bfill\n",
        "\n",
        "Q8B: Write your modified `DataFrame` from Q11A to a `.csv` file. Your answer for these items should include a Python program + comments that document process and explain your code.\n"
      ],
      "metadata": {
        "id": "9UsCZ4ANt0dy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to Submit This Lab (and show your work)\n",
        "\n",
        "Moving forward, we're going to be submitting lab notebooks using the provide Jupyter Notebook template ([link for this lab's template](https://colab.research.google.com/drive/1sKrGhGa_uvJw7l4QiKGKP-X_sAMlcQrq?usp=sharing)).\n",
        "- If working in JupyterLab (or another desktop IDE), download the `.ipynb` file to your local computer\n",
        "  * `File` - `Download` - `Download as .ipynb`\n",
        "- If working in Google Colaboratory, MAKE SURE you save a copy to your local drive. Otherwise your changes will not be saved.\n",
        "  * `File` - `Save a copy in Drive`\n",
        "\n",
        "The lab notebook template includes all of the questions as well as pre-created markdown cells for narrative text answers and pre-created code cells for any programs you may need to create. \n",
        "- Double click on these cells to edit and add your own content\n",
        "- If questions do not require a code component, you can ignore those cells\n",
        "- If questions to not require a narrative component, you can ignore those cells\n",
        "\n",
        "If working in JupyterLab or another desktop IDE, upload the lab notebook template `.ipynb` file to Canvas as your lab submission.\n",
        "- NOTE: This lab also asks you to upload a PDF version of this notebook. You are welcome, but not required, to do that moving forward.\n",
        "\n",
        "If working in Google Colaboratory, submit the link to your notebook (checking sharing permissions, similar with Google Docs) AS WELL AS the `.ipyb` file"
      ],
      "metadata": {
        "id": "sq19khkGt10w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Notebook Questions\n",
        "\n",
        "[Click here](https://colab.research.google.com/drive/1sKrGhGa_uvJw7l4QiKGKP-X_sAMlcQrq?usp=sharing) to access the lab notebook template as a Jupyter Notebook (Google Colab, ND Users)\n",
        "\n",
        "Q1: Describe a `Series` object in your own words.\n",
        "\n",
        "Q2: Create your own `Series` object. Write code the accomplishes the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Assign unique index attributes for each series value\n",
        "- Access a series value(s) using the index label\n",
        "- Perform at least two unique arithmetic operations on the Series\n",
        "- Test for null values in your series\n",
        "\n",
        "Q3: Describe a DataFrame in your own words.\n",
        "\n",
        "Q4: Create your own small DataFrame. Write code that accomplishes the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "\n",
        "- Change the original column order\n",
        "- Select a specific column(s) using its index label or name attribute\n",
        "- Select a specific row(s) using its index label or index value\n",
        "- Remove a column from the DataFrame\n",
        "- Determine summary statistics for values in the DataFrame\n",
        "\n",
        "Q5: Write code that loads in a different `.csv` file as a DataFrame and accomplishes each of the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "\n",
        "- Shows the first five rows\n",
        "- Shows the last five rows\n",
        "- Checks the data types for each column\n",
        "- Returns a technical summary for the DataFrame\n",
        "\n",
        "For the Q6 programs, you do not need to write code that actually loads an existing data file. That is, the lab does not provide data files that include these structures/attributes.\n",
        "\n",
        "Write sample code that shows the syntax you would use to load a file with the structures/attributes described in the question.\n",
        "\n",
        "For example, your answers might look something like the sample syntax shown in the previous section of the lab..\n",
        "\n",
        "HINT: Be prepared to reference and consult the additional pd.read_csv function arguments listed in the previous lab section's tables.\n",
        "\n",
        "Q6A: Write code that loads in a structured data file that uses a pipe symbol (|) as a delimiter. Include code + comments.\n",
        " \n",
        "Q6B: Write code that loads in structured data file in which missing data values are represented by \"?\", \"??\", and \"-\" characters. Include code + comments.\n",
        "\n",
        "Q6C: Write code that ignores the last 6 rows of a structured data file. Include code + comments.\n",
        "\n",
        "Q6D: Write code that parses a structured data file in which commas \",\" are used as a thousands separator. Include code + comments\n",
        "\n",
        "Q7A: Using the DataFrame you created for Q5, write code that executes AT LEAST FOUR of the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Sorts a column by ascending values\n",
        "- Sorts a column by descending values\n",
        "- Selects a specific column in the DataFrame\n",
        "- Creates a new DataFrame with select columns from existing DataFrame\n",
        "- Uses a comparison operator to filter rows in the DataFrame\n",
        "- Uses an isin statement to filter rows in the DataFrame\n",
        "- Selects specific rows and columns\n",
        "\n",
        "Q7B: Write your modified `DataFrame` from Q7A to a `.csv` file. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "\n",
        "Q8A: Using the DataFrame you created for Q5 (and used in Q7), write code that executes AT LEAST ONE of the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "\n",
        "- Removes duplicate rows\n",
        "- Removes rows with missing values\n",
        "- Fills missing values using .fillna, ffill, or bfill\n",
        "\n",
        "Q8B: Write your modified `DataFrame` from Q11A to a `.csv` file. Your answer for these items should include a Python program + comments that document process and explain your code."
      ],
      "metadata": {
        "id": "NA5lvHpjt2q0"
      }
    }
  ]
}